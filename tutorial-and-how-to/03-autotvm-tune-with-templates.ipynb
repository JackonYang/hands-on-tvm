{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Tune with Templates and AutoTVM\n",
    "\n",
    "官网 doc: https://tvm.apache.org/docs/how_to/tune_with_autotvm/index.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tvm\n",
    "from tvm import relay, autotvm\n",
    "from tvm.relay import testing\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "from tvm.autotvm.graph_tuner import DPTuner, PBQPTuner\n",
    "import tvm.contrib.graph_executor as runtime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 准备材料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "dtype = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet-18'\n",
    "n_layer = int(model_name.split('-')[-1])\n",
    "mod, params = relay.testing.resnet.get_workload(\n",
    "    num_layers=n_layer, batch_size=batch_size, dtype=dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'mobilenet'\n",
    "# mod, params = relay.testing.mobilenet.get_workload(batch_size=batch_size, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm\"\n",
    "log_file = \"%s.log\" % model_name\n",
    "graph_opt_sch_file = \"%s_graph_opt.log\" % model_name\n",
    "\n",
    "# Set the input name of the graph\n",
    "# For ONNX models, it is typically \"0\".\n",
    "input_name = \"data\"\n",
    "\n",
    "# Set number of threads used for tuning based on the number of\n",
    "# physical CPU cores on your machine.\n",
    "num_threads = 1\n",
    "os.environ[\"TVM_NUM_THREADS\"] = str(num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_option = {\n",
    "    \"log_filename\": log_file,\n",
    "    \"tuner\": \"random\",\n",
    "    \"early_stopping\": None,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(),\n",
    "        runner=autotvm.LocalRunner(\n",
    "            number=1, repeat=10, min_repeat_ms=0, enable_cpu_cache_flush=True\n",
    "        ),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use graph tuner to achieve graph level optimal schedules\n",
    "# Set use_DP=False if it takes too long to finish.\n",
    "def tune_graph(graph, dshape, records, opt_sch_file, use_DP=True):\n",
    "    target_op = [\n",
    "        relay.op.get(\"nn.conv2d\"),\n",
    "    ]\n",
    "    Tuner = DPTuner if use_DP else PBQPTuner\n",
    "    executor = Tuner(graph, {input_name: dshape}, records, target_op, target)\n",
    "    executor.benchmark_layout_transform(min_exec_num=2000)\n",
    "    executor.run()\n",
    "    executor.write_opt_sch2record_file(opt_sch_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(lib, data_shape):\n",
    "    # upload parameters to device\n",
    "    dev = tvm.cpu()\n",
    "    data_tvm = tvm.nd.array((np.random.uniform(size=data_shape)).astype(dtype))\n",
    "    module = runtime.GraphModule(lib[\"default\"](dev))\n",
    "    module.set_input(input_name, data_tvm)\n",
    "\n",
    "    # evaluate\n",
    "    print(\"Evaluate inference time cost...\")\n",
    "    print(module.benchmark(dev, number=100, repeat=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate(tuning_opt):\n",
    "    # extract workloads from relay program\n",
    "    print(\"Extract tasks...\")\n",
    "    mod, params, data_shape, out_shape = get_network(model_name, batch_size)\n",
    "    tasks = autotvm.task.extract_from_program(\n",
    "        mod[\"main\"], target=target, params=params, ops=(relay.op.get(\"nn.conv2d\"),)\n",
    "    )\n",
    "\n",
    "    # run tuning tasks\n",
    "    # tune_kernels(tasks, **tuning_opt)\n",
    "    tune_graph(mod[\"main\"], data_shape, log_file, graph_opt_sch_file)\n",
    "\n",
    "    # compile kernels in default mode\n",
    "    print(\"Evaluation of the network compiled in 'default' mode without auto tune:\")\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        print(\"Compile...\")\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "        evaluate_performance(lib, data_shape)\n",
    "\n",
    "    # compile kernels in kernel tuned only mode\n",
    "    print(\"\\nEvaluation of the network been tuned on kernel level:\")\n",
    "    with autotvm.apply_history_best(log_file):\n",
    "        print(\"Compile...\")\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = relay.build(mod, target=target, params=params)\n",
    "        evaluate_performance(lib, data_shape)\n",
    "\n",
    "    # compile kernels with graph-level best records\n",
    "    print(\"\\nEvaluation of the network been tuned on graph level:\")\n",
    "    with autotvm.apply_graph_best(graph_opt_sch_file):\n",
    "        print(\"Compile...\")\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            lib = relay.build_module.build(mod, target=target, params=params)\n",
    "        evaluate_performance(lib, data_shape)\n",
    "\n",
    "# do not run the tuning in our webpage server since it takes too long.\n",
    "tune_and_evaluate(tuning_option)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
